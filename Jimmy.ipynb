{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4d27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f8a27",
   "metadata": {},
   "source": [
    "#### Load\n",
    "\n",
    "json, etc. https://www.realpythonproject.com/a-cheat-sheet-for-working-with-json-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ce48a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING DUMB DUMP BUG\n",
    "\"\"\"\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "DATA_FILES = list(map(\n",
    "                    lambda f: os.path.join(DATA_DIR, f), os.listdir(DATA_DIR)\n",
    "                ))\n",
    "\n",
    "for fp in DATA_FILES:\n",
    "    filename = fp.split('/')[-1]\n",
    "    NEW_DATA_PATH = os.path.join(os.getcwd(), 'data', f'fix__{filename}')\n",
    "    with open(fp, 'r') as rf, open(NEW_DATA_PATH, 'w') as wf:\n",
    "        tmp = rf.readlines()\n",
    "        data = []\n",
    "        \n",
    "        wf.write('[')\n",
    "        for line in tmp:\n",
    "            if line[:2] == '}{':\n",
    "                data.append('},{\\n')\n",
    "            else:\n",
    "                data.append(line)\n",
    "\n",
    "        wf.writelines(data)\n",
    "        wf.write(']')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one (sample)\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'data', 'fix__2020-04-20__0.json')\n",
    "\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    tmp = json.load(f)\n",
    "    df = pd.DataFrame(tmp)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b843852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99975 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   author_id            99975 non-null  int64  \n",
      " 1   id                   99975 non-null  int64  \n",
      " 2   in_reply_to_user_id  29159 non-null  float64\n",
      " 3   created_at           99975 non-null  object \n",
      " 4   lang                 99975 non-null  object \n",
      " 5   text                 99975 non-null  object \n",
      " 6   possibly_sensitive   99975 non-null  bool   \n",
      " 7   source               99975 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(2), object(4)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load all\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "DATA_FILES = list(map(\n",
    "                    lambda f: os.path.join(DATA_DIR, f), os.listdir(DATA_DIR)\n",
    "                ))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for fp in DATA_FILES:\n",
    "    with open(fp, 'r') as f:\n",
    "        tmp = json.load(f)\n",
    "        tmp = pd.DataFrame(tmp)\n",
    "    \n",
    "    df = pd.concat([df, tmp])\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927eded9",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7b20f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>711679239</td>\n",
       "      <td>1516700055759118337</td>\n",
       "      <td>208429848.0</td>\n",
       "      <td>2022-04-20 08:47:26.000000</td>\n",
       "      <td>und</td>\n",
       "      <td>@Crypto_Niazi #FEG</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1376829402122575872</td>\n",
       "      <td>1516700055759114244</td>\n",
       "      <td>241214642.0</td>\n",
       "      <td>2022-04-20 08:47:26.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>@dexamol_ @NoCreative_eth @Paddy_Stash @HChipN...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463462196499804162</td>\n",
       "      <td>1516700055641935873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>â€œWhen you have a dream, youâ€™ve got to grab it ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500281789797236737</td>\n",
       "      <td>1516700055537094656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>The rumours are not true. We will not be prici...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1187027027637014528</td>\n",
       "      <td>1516700055427854340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>I just listed this bored ape NFT for 20 ETH in...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                   id  in_reply_to_user_id  \\\n",
       "0            711679239  1516700055759118337          208429848.0   \n",
       "1  1376829402122575872  1516700055759114244          241214642.0   \n",
       "2  1463462196499804162  1516700055641935873                  NaN   \n",
       "3  1500281789797236737  1516700055537094656                  NaN   \n",
       "4  1187027027637014528  1516700055427854340                  NaN   \n",
       "\n",
       "                   created_at lang  \\\n",
       "0  2022-04-20 08:47:26.000000  und   \n",
       "1  2022-04-20 08:47:26.000000   en   \n",
       "2  2022-04-20 08:47:26.000000   en   \n",
       "3  2022-04-20 08:47:26.000000   en   \n",
       "4  2022-04-20 08:47:26.000000   en   \n",
       "\n",
       "                                                text  possibly_sensitive  \\\n",
       "0                                 @Crypto_Niazi #FEG               False   \n",
       "1  @dexamol_ @NoCreative_eth @Paddy_Stash @HChipN...               False   \n",
       "2  â€œWhen you have a dream, youâ€™ve got to grab it ...               False   \n",
       "3  The rumours are not true. We will not be prici...               False   \n",
       "4  I just listed this bored ape NFT for 20 ETH in...               False   \n",
       "\n",
       "                source  \n",
       "0   Twitter for iPhone  \n",
       "1      Twitter Web App  \n",
       "2      Twitter Web App  \n",
       "3      Twitter Web App  \n",
       "4  Twitter for Android  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6100b05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645f7407",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778,\n",
       " array(['Twitter for iPhone', 'Twitter Web App', 'Twitter for Android',\n",
       "        'TwitterTestingApp7', 'abnormal_crypto_app', 'TweetApp for iPhone',\n",
       "        'IFTTT', 'TweetApp for Android', 'Tweep+', 'Twitter'], dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.source.unique()), df.source.unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "583dccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate\n",
    "df = df[~df.text.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a209c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2022-04-20 08:47:26\n",
       "1      2022-04-20 08:47:26\n",
       "2      2022-04-20 08:47:26\n",
       "3      2022-04-20 08:47:26\n",
       "4      2022-04-20 08:47:26\n",
       "               ...        \n",
       "9982   2022-04-20 07:07:53\n",
       "9989   2022-04-20 07:07:53\n",
       "9990   2022-04-20 07:07:53\n",
       "9994   2022-04-20 07:07:53\n",
       "9999   2022-04-20 07:07:53\n",
       "Name: created_at, Length: 51569, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.created_at = pd.to_datetime(df.created_at)\n",
    "df.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d1a1f3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-04-20 06:22:10')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.created_at.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8bc6e",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c01991a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13536"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.lang != 'en')\n",
    "\n",
    "# skip translate; kelamaan.... (13k ~ 4 jam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9cf3b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38033, 9)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.lang == 'en']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880712c",
   "metadata": {},
   "source": [
    "##### Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1d3f325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator as GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a22aeeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From\n",
    "# https://stackoverflow.com/a/58356570/8996974\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47b55aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Crypto_Niazi #FEG\n",
      "@dexamol_ @NoCreative_eth @Paddy_Stash @HChipNFT @kukulabanze This is such a cool concept!\n",
      "â€œWhen you have a dream, youâ€™ve got to grab it and never let go.â€\n",
      "@sapeofficialeth is my dream whatâ€™s yourâ€™s \n",
      "https://t.co/e8pvUvkd3J\n",
      "#bsape  #sape #safuape #crypto #eth #btc @sapeofficialeth https://t.co/IEc0awVfns https://t.co/vPoi5M4yUb\n",
      "The rumours are not true. We will not be pricing @SmartPiggyNFT at 0.25 $ETH... if you guess our Mint Price you get a free NFT and $25 in ETH #HotMama ðŸ˜±\n",
      ".\n",
      ".\n",
      ".\n",
      "#NFTCommunity #NFTsales #NFTgiveaway #NFTAlpha #NFTGiveaways #FreeNFT #FreeNFTs #fearthepiggy #smartpiggy #trending https://t.co/rCBPCtcooq\n",
      "I just listed this bored ape NFT for 20 ETH in Opensea https://t.co/UQyWo73uI2\n"
     ]
    }
   ],
   "source": [
    "def print_5(df):\n",
    "    for t in df.text.iloc[:5]:\n",
    "        print(t)\n",
    "        \n",
    "print_5(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "017138f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f91398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Crypto_Niazi #FEG\n",
      "@dexamol_ @NoCreative_eth @Paddy_Stash @HChipNFT @kukulabanze This is such a cool concept!\n",
      "â€œWhen you have a dream, youâ€™ve got to grab it and never let go.â€\n",
      "@sapeofficialeth is my dream whatâ€™s yourâ€™s \n",
      "https://t.co/e8pvUvkd3J\n",
      "#bsape  #sape #safuape #crypto #eth #btc @sapeofficialeth https://t.co/IEc0awVfns https://t.co/vPoi5M4yUb\n",
      "The rumours are not true. We will not be pricing @SmartPiggyNFT at 0.25 $ETH... if you guess our Mint Price you get a free NFT and $25 in ETH #HotMama \n",
      ".\n",
      ".\n",
      ".\n",
      "#NFTCommunity #NFTsales #NFTgiveaway #NFTAlpha #NFTGiveaways #FreeNFT #FreeNFTs #fearthepiggy #smartpiggy #trending https://t.co/rCBPCtcooq\n",
      "I just listed this bored ape NFT for 20 ETH in Opensea https://t.co/UQyWo73uI2\n"
     ]
    }
   ],
   "source": [
    "print_5(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12908eec",
   "metadata": {},
   "source": [
    "##### Text\n",
    "\n",
    "[Contekan](https://github.com/bayhaqy/analisa-sentimen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4249089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From\n",
    "# https://github.com/ssut/py-googletrans/issues/301#issuecomment-888261389\n",
    "from time import sleep\n",
    "import backoff\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self):\n",
    "        self.client = GoogleTranslator()\n",
    "        self.sleep_in_between_translations_seconds = 1\n",
    "        self.source_language = \"en\"\n",
    "        self.max_chunk_size = 4000\n",
    "\n",
    "    def __createChunks(self, corpus):\n",
    "        chunks = [corpus[i:i + self.max_chunk_size] for i in range(0, len(corpus), self.max_chunk_size)]\n",
    "        return chunks\n",
    "\n",
    "    def __sleepBetweenQuery(self):\n",
    "        print('Sleeping for {}s after translation query..'.format(self.sleep_in_between_translations_seconds))\n",
    "        sleep(self.sleep_in_between_translations_seconds)\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception, max_tries=150)\n",
    "    def Translate(self, content, dest_language_code):\n",
    "        try:\n",
    "            print('Attempting to translate to lang={}'.format(dest_language_code))\n",
    "            if len(content) > self.max_chunk_size:\n",
    "                print('Warning: Content is longer than allowed size of {}, breaking into chunks'.format(self.max_chunk_size))\n",
    "                results_list = []\n",
    "                concatenated_result = \"\"\n",
    "\n",
    "                original_chunks = self.__createChunks(content)\n",
    "                for i in original_chunks:\n",
    "                    r = self.client.translate(i, dest=dest_language_code, src=self.source_language)\n",
    "                    self.__sleepBetweenQuery()\n",
    "                    results_list.append(r.text)\n",
    "\n",
    "                for i in results_list:\n",
    "                    concatenated_result += i\n",
    "\n",
    "                return concatenated_result\n",
    "            else:\n",
    "                res = self.client.translate(content, dest=dest_language_code, src=self.source_language)\n",
    "                self.__sleepBetweenQuery()\n",
    "                return res.text\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7a01d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace karakter berulang\n",
    "def hapus_katadouble(tweet):\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", tweet)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Case folding\n",
    "    tweet = tweet.lower()\n",
    "  \n",
    "    # Cleansing (Remove URL)\n",
    "#     tweet = re.sub('http\\S+|\\S+co\\S+', ' ', tweet)\n",
    "    tweet = re.sub('http\\S+|\\S+co\\S+', '', tweet)\n",
    "    \n",
    "    # Cleansing (Remove Mention)\n",
    "    tweet = re.sub(\"@[A-Za-z0-9\\S]+\", \"\", tweet)\n",
    "  \n",
    "    # Cleansing (Remove Hastag)\n",
    "#     tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'', tweet)\n",
    "    \n",
    "    # Cleansing (Remove Number and Punctuation)\n",
    "    wrem_list = ('rt',)\n",
    "    exclude = set (string.punctuation)\n",
    "    rem_list = []\n",
    "    token = tweet.split()\n",
    "    for w in token:\n",
    "        if w not in wrem_list:\n",
    "            for x in w:\n",
    "                if x in exclude or x.isdigit():\n",
    "                    rem_list.append(\"\")\n",
    "                else:\n",
    "                    rem_list.append(x)\n",
    "            rem_list.append(\" \")\n",
    "    tweet = \"\".join(rem_list)\n",
    "  \n",
    "    tweet = hapus_katadouble(tweet)\n",
    "  \n",
    "    # hapus extra space dalam kalimat\n",
    "    return \" \".join(tweet.split())\n",
    "\n",
    "\n",
    "# masukkan stopord tambahan\n",
    "STOP_TAMBAH = None\n",
    "extra_stopwords = os.path.join(os.getcwd(), 'extras', 'stop_tambah.txt')\n",
    "with open(extra_stopwords) as f:\n",
    "    tmp = f.readlines()\n",
    "    STOP_TAMBAH = set(map(lambda x: x.rstrip('\\n'), tmp))\n",
    "\n",
    "# Preprocessing english\n",
    "def preprocessing_en(tweet):\n",
    "\n",
    "    # PorterStemmer English dari library NLTK\n",
    "    stemmer = PorterStemmer()\n",
    "    #stemmer = WordNetLemmatizer()\n",
    "\n",
    "    token_words = word_tokenize(tweet)\n",
    "    sentence = []\n",
    "    for word in token_words:\n",
    "        if word not in STOP_TAMBAH and len(word) > 1 and len(word) < 25:   \n",
    "            sentence.append(stemmer.stem(word))\n",
    "            #sentence.append(stemmer.lemmatize(word,pos='v'))\n",
    "    return sentence\n",
    "  \n",
    "\n",
    "# Translate ke English menggunakan Google Translate\n",
    "def gtrans_tweet_en(tweet, lang):\n",
    "    if not tweet:\n",
    "        return None\n",
    "    \n",
    "    if lang == \"en\":\n",
    "        return tweet\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lang = GoogleTranslator().detect(tweet).lang\n",
    "    except:\n",
    "        return None\n",
    "    \"\"\"\n",
    "    \n",
    "    translator = Translator()\n",
    "    text = translator.Translate(tweet, dest='en').text\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Klasifikasi Polaritas Tweet menggunakan Vader\n",
    "def sentiment_Vader(tweet):\n",
    "    analysis = SentimentIntensityAnalyzer()\n",
    "    analysis = analysis.polarity_scores(tweet)\n",
    "    comm = analysis['compound']\n",
    "    if (comm >= 0.05):\n",
    "        return \"Positive\"\n",
    "    elif ((comm > -0.05) and (comm < 0.05)):\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Cek analisis sentimen dari English tweet menggunakan VADER\n",
    "def sentiment_analysis_en(tweet):\n",
    "    tweet = clean_tweet(tweet)\n",
    "    \n",
    "    # NO PREPROCESSING HAPPENS HERE\n",
    "    \n",
    "    tweet = gtrans_tweet_en(tweet)\n",
    "    sentiment = sentiment_Vader(tweet)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32f54c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumours are not true we will not be pricing at eth if you guess our mint price you get a free nft and in eth'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "clean_tweet(df.text.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7850177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all in one, not preprocessed\n",
    "# df['sentiment'] = df.text.apply(sentiment_analysis_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bcacf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df.text.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8006a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard empty string\n",
    "df = df[df.clean_tweet != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fb3026ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591 ms Â± 105 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# SKIP TRANSLATE\n",
    "# sample = df.iloc[0:10].copy()\n",
    "# sample['clean_tweet_en'] = sample.apply(lambda x: gtrans_tweet_en(x['clean_tweet'], x['lang']), axis=1)\n",
    "%timeit df['clean_tweet_en'] = df.apply(lambda x: gtrans_tweet_en(x['clean_tweet'], x['lang']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6aadde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample = df.iloc[0:10000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a1ab1b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.592994689941406\n"
     ]
    }
   ],
   "source": [
    "\"\"\"5 detik per 10k data\"\"\"\n",
    "# %timeit df['preprocessed'] = df.clean_tweet_en.apply(preprocessing_en)\n",
    "start = time.time()\n",
    "sample['preprocessed'] = sample.clean_tweet_en.apply(preprocessing_en)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb77818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['preprocessed'] = df.clean_tweet_en.apply(preprocessing_en)\n",
    "# df['sentiment_clean_en'] = df.clean_tweet_en.apply(sentiment_Vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8538126e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.03955078125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2 menit per 10k data\"\"\"\n",
    "# %timeit df['sentiment_clean_en'] = df.clean_tweet_en.apply(sentiment_Vader)\n",
    "start = time.time()\n",
    "sample['sentiment_clean_en'] = sample.clean_tweet_en.apply(sentiment_Vader)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "07067141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_en</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>sentiment_clean_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1376829402122575872</td>\n",
       "      <td>1516700055759114244</td>\n",
       "      <td>241214642.0</td>\n",
       "      <td>2022-04-20 08:47:26</td>\n",
       "      <td>en</td>\n",
       "      <td>@dexamol_ @NoCreative_eth @Paddy_Stash @HChipN...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>this is such a cool concept</td>\n",
       "      <td>this is such a cool concept</td>\n",
       "      <td>[cool, concept]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463462196499804162</td>\n",
       "      <td>1516700055641935873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26</td>\n",
       "      <td>en</td>\n",
       "      <td>â€œWhen you have a dream, youâ€™ve got to grab it ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>â€œwhen you have a dream youâ€™ve got to grab it a...</td>\n",
       "      <td>â€œwhen you have a dream youâ€™ve got to grab it a...</td>\n",
       "      <td>[dream, grab, never, dream]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500281789797236737</td>\n",
       "      <td>1516700055537094656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26</td>\n",
       "      <td>en</td>\n",
       "      <td>The rumours are not true. We will not be prici...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>the rumours are not true we will not be pricin...</td>\n",
       "      <td>the rumours are not true we will not be pricin...</td>\n",
       "      <td>[rumour, not, true, will, not, price, eth, if,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1187027027637014528</td>\n",
       "      <td>1516700055427854340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26</td>\n",
       "      <td>en</td>\n",
       "      <td>I just listed this bored ape NFT for 20 ETH in...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>i just listed this bored ape nft for eth in op...</td>\n",
       "      <td>i just listed this bored ape nft for eth in op...</td>\n",
       "      <td>[list, bore, ape, nft, eth, opensea]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1502908260659179521</td>\n",
       "      <td>1516700055423623172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-20 08:47:26</td>\n",
       "      <td>en</td>\n",
       "      <td>Fuck it. Drop your $ETH wallets\\n\\nRT, Like\\nF...</td>\n",
       "      <td>False</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>fuck it drop your eth wallets rt like follow me</td>\n",
       "      <td>fuck it drop your eth wallets rt like follow me</td>\n",
       "      <td>[fuck, drop, eth, wallet, follow]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                   id  in_reply_to_user_id  \\\n",
       "1  1376829402122575872  1516700055759114244          241214642.0   \n",
       "2  1463462196499804162  1516700055641935873                  NaN   \n",
       "3  1500281789797236737  1516700055537094656                  NaN   \n",
       "4  1187027027637014528  1516700055427854340                  NaN   \n",
       "5  1502908260659179521  1516700055423623172                  NaN   \n",
       "\n",
       "           created_at lang                                               text  \\\n",
       "1 2022-04-20 08:47:26   en  @dexamol_ @NoCreative_eth @Paddy_Stash @HChipN...   \n",
       "2 2022-04-20 08:47:26   en  â€œWhen you have a dream, youâ€™ve got to grab it ...   \n",
       "3 2022-04-20 08:47:26   en  The rumours are not true. We will not be prici...   \n",
       "4 2022-04-20 08:47:26   en  I just listed this bored ape NFT for 20 ETH in...   \n",
       "5 2022-04-20 08:47:26   en  Fuck it. Drop your $ETH wallets\\n\\nRT, Like\\nF...   \n",
       "\n",
       "   possibly_sensitive               source  \\\n",
       "1               False      Twitter Web App   \n",
       "2               False      Twitter Web App   \n",
       "3               False      Twitter Web App   \n",
       "4               False  Twitter for Android   \n",
       "5               False  Twitter for Android   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "1                        this is such a cool concept   \n",
       "2  â€œwhen you have a dream youâ€™ve got to grab it a...   \n",
       "3  the rumours are not true we will not be pricin...   \n",
       "4  i just listed this bored ape nft for eth in op...   \n",
       "5    fuck it drop your eth wallets rt like follow me   \n",
       "\n",
       "                                      clean_tweet_en  \\\n",
       "1                        this is such a cool concept   \n",
       "2  â€œwhen you have a dream youâ€™ve got to grab it a...   \n",
       "3  the rumours are not true we will not be pricin...   \n",
       "4  i just listed this bored ape nft for eth in op...   \n",
       "5    fuck it drop your eth wallets rt like follow me   \n",
       "\n",
       "                                        preprocessed sentiment_clean_en  \n",
       "1                                    [cool, concept]           Positive  \n",
       "2                        [dream, grab, never, dream]           Positive  \n",
       "3  [rumour, not, true, will, not, price, eth, if,...           Positive  \n",
       "4               [list, bore, ape, nft, eth, opensea]           Negative  \n",
       "5                  [fuck, drop, eth, wallet, follow]           Negative  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9449d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(os.getcwd(), 'extras', 'checkpoint.csv')\n",
    "sample.to_csv(CHECKPOINT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab94c99",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a97b70",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa627e7",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c45059",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d59b7",
   "metadata": {},
   "source": [
    "#### Viz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
